{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vnet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OxW_hURYSxnD",
        "U81P_VgkTvQ3",
        "hF3HMPOhTqnw",
        "M5zF9NFATlkK",
        "Z12H7aUfTf53"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KFQll7BVg7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d22Fh-HFMFO",
        "colab_type": "text"
      },
      "source": [
        "# Vnet(propsesd architecture) for different datasets and comparision with existing models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxW_hURYSxnD",
        "colab_type": "text"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOfy_3oKWGmO",
        "colab_type": "code",
        "outputId": "05d8f351-32f4-4aab-afb7-070a32ace520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize((28,28)),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,), (0.5,))\n",
        "                               ])\n",
        "training_dataset = datasets.MNIST(root='./data1', train=True, download=True, transform=transform)\n",
        "validation_dataset = datasets.MNIST(root='./data2', train=False, download=True, transform=transform)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data1/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:03, 3298715.67it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data1/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data1/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 47679.79it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data1/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data1/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:02, 798804.80it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data1/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data1/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 18030.55it/s]            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data1/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data2/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:03, 3306507.02it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data2/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data2/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 47937.36it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data2/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data2/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:02, 788925.37it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data2/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data2/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 17893.87it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data2/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpo3pt8AWI7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def im_convert(tensor):\n",
        "  image = tensor.cpu().clone().detach().numpy()\n",
        "  image = image.transpose(1, 2, 0)\n",
        "  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n",
        "  image = image.clip(0, 1)\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOGr_Lt7WLij",
        "colab_type": "code",
        "outputId": "c24af5a8-fc25-4ecc-f61c-787e1337ba2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "dataiter = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "\n",
        "for idx in np.arange(20):\n",
        "  ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
        "  plt.imshow(im_convert(images[idx]))\n",
        "  ax.set_title([labels[idx].item()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABXUAAAD7CAYAAAAl6XdWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1800x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU86DIYWr0Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A047ySEEeNn",
        "colab_type": "text"
      },
      "source": [
        "## VNet For MNIST digit classfication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0WusxWCqGL2",
        "colab_type": "code",
        "outputId": "ff5d6db3-e426-4adb-b7b5-042e8971c0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# m= nn.Conv2d(20, 50, 5, 1)\n",
        "# input = torch.randn(1, 20, 24, 24)\n",
        "# output = m(input)\n",
        "# output.shape\n",
        "# # torch.Size([20, 20, 24, 24])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 50, 20, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUqLn0ZWXwUm",
        "colab_type": "code",
        "outputId": "ffb6d781-a9a7-4a77-dffa-f928a3fb3624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "class VNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv_X1 = nn.Conv2d(1,20,5,1)\n",
        "    self.conv_X2 = nn.Conv2d(20,30,5,1)\n",
        "    self.conv_X3 = nn.Conv2d(30,40,4,1)\n",
        "    \n",
        "    self.conv_Y1 = nn.Conv2d(1,20,5,1)\n",
        "    self.conv_Y2 = nn.Conv2d(20,30,5,1)\n",
        "    self.conv_Y3 = nn.Conv2d(30,40,4,1)\n",
        "    \n",
        "    self.conv_Z1 = nn.Conv2d(1,20,5,1)\n",
        "    self.conv_Z2 = nn.Conv2d(20,30,5,1)\n",
        "    self.conv_Z3 = nn.Conv2d(30,40,4,1)\n",
        "    \n",
        "    self.conv_Xinter = nn.Conv2d(20,30,5,1)\n",
        "    self.conv_Yinter = nn.Conv2d(30,40,4,1)\n",
        "    self.conv_Zinter = nn.Conv2d(40,50,1,1)\n",
        "    \n",
        "    self.fc1=nn.Linear(480,500)\n",
        "    self.fc2=nn.Linear(40,100)\n",
        "    self.fc3=nn.Linear(50,100)\n",
        "    self.dropout1 = nn.Dropout(0.5)\n",
        "    self.fc = nn.Linear(700, 10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    si=x.size(0)\n",
        "    x1 = F.relu(self.conv_X1(x))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    xinter =x1\n",
        "    \n",
        "    x1 = F.relu(self.conv_X2(x1))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    x1 = F.relu(self.conv_X3(x1))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    \n",
        "    x2 = F.relu(self.conv_Y1(x))\n",
        "    x2 = F.max_pool2d(x2,2,2)\n",
        "    x2 = F.relu(self.conv_Y2(x2))\n",
        "    x2 = F.max_pool2d(x2,2,2)\n",
        "    yinter = x2\n",
        "    x2 = F.relu(self.conv_Y3(x2))\n",
        "    x2= F.max_pool2d(x2,2,2)\n",
        "    \n",
        "    x3 = F.relu(self.conv_Z1(x))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    x3 = F.relu(self.conv_Z2(x3))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    x3 = F.relu(self.conv_Z3(x3))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    zinter=x3\n",
        "    \n",
        "    xinter = F.relu(self.conv_Xinter(xinter))\n",
        "    xinter = F.max_pool2d(xinter,2,2)\n",
        "    yinter = F.relu(self.conv_Yinter(yinter))\n",
        "    yinter = F.max_pool2d(yinter,2,2)\n",
        "    zinter = F.relu(self.conv_Zinter(zinter))\n",
        "    zinter = F.max_pool2d(zinter,2,2)\n",
        "    \n",
        "    xinter = xinter.view(si,-1)\n",
        "    xinter = F.relu(self.fc1(xinter))\n",
        "    xinter = self.dropout1(xinter)\n",
        "    \n",
        "    yinter = yinter.view(si,-1)\n",
        "    yinter = F.relu(self.fc2(yinter))\n",
        "    yinter = self.dropout1(yinter)\n",
        "    \n",
        "    zinter = zinter.view(si,-1)\n",
        "    zinter = F.relu(self.fc3(zinter))\n",
        "    zinter = self.dropout1(zinter)\n",
        "    \n",
        "    flatten=torch.cat((xinter,yinter,zinter),dim=1)\n",
        "#     flatten=torch.cat((flatten,zinter),dim=1)\n",
        "    \n",
        "    return self.fc(flatten)\n",
        "    \n",
        "    \n",
        "    \n",
        "model=VNet().to(device)\n",
        "model\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VNet(\n",
              "  (conv_X1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_X2): Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_X3): Conv2d(30, 40, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (conv_Y1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_Y2): Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_Y3): Conv2d(30, 40, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (conv_Z1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_Z2): Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_Z3): Conv2d(30, 40, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (conv_Xinter): Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_Yinter): Conv2d(30, 40, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (conv_Zinter): Conv2d(40, 50, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=480, out_features=500, bias=True)\n",
              "  (fc2): Linear(in_features=40, out_features=100, bias=True)\n",
              "  (fc3): Linear(in_features=50, out_features=100, bias=True)\n",
              "  (dropout1): Dropout(p=0.5)\n",
              "  (fc): Linear(in_features=700, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5_lponHEkEZ",
        "colab_type": "text"
      },
      "source": [
        "## VNet Version2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBFCviQSyd73",
        "colab_type": "code",
        "outputId": "7b0f1c98-7566-491e-ea0c-dd8381dd63ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "class VNetModified(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv_X1 = nn.Conv2d(1,20,5,1)\n",
        "    self.conv_X2 = nn.Conv2d(20,30,5,1)\n",
        "    self.conv_X3 = nn.Conv2d(30,40,4,1)\n",
        "    \n",
        "    self.conv_Y1 = nn.Conv2d(1,20,5,1)\n",
        "    self.conv_Y2 = nn.Conv2d(20,30,5,1)\n",
        "    self.conv_Y3 = nn.Conv2d(30,40,4,1)\n",
        "    \n",
        "    self.conv_Z1 = nn.Conv2d(1,20,5,1)\n",
        "    self.conv_Z2 = nn.Conv2d(20,30,5,1)\n",
        "    self.conv_Z3 = nn.Conv2d(30,40,4,1)\n",
        "    \n",
        "    self.conv_Xinter = nn.Conv2d(20,30,5,1)\n",
        "    self.conv_Yinter = nn.Conv2d(30,40,4,1)\n",
        "    self.conv_Zinter = nn.Conv2d(40,50,1,1)\n",
        "    \n",
        "    self.fc_Xinter=nn.Linear(480,500)\n",
        "    self.fc_Yinter=nn.Linear(40,100)\n",
        "    self.fc_Zinter=nn.Linear(50,100)\n",
        "    \n",
        "    self.fc_Xend=nn.Linear(40,100)\n",
        "    self.fc_Yend=nn.Linear(40,100)\n",
        "    self.fc_Zend =nn.Linear(40,100)\n",
        "    \n",
        "    self.dropout_Xinter = nn.Dropout(0.5)\n",
        "    self.dropout_Yinter = nn.Dropout(0.5)\n",
        "    self.dropout_Zinter = nn.Dropout(0.5)\n",
        "     \n",
        "    self.dropout_Xend = nn.Dropout(0.5)\n",
        "    self.dropout_Yend = nn.Dropout(0.5)\n",
        "    self.dropout_Zend = nn.Dropout(0.5)\n",
        "    \n",
        "#     self.dropout1 =nn.Dropout(0.5)\n",
        "#     self.dropout2 =nn.Dropout(0.5)\n",
        "    \n",
        "    self.fc1 = nn.Linear(1000, 10)\n",
        "#     self.fc2 = nn.Linear(784, 256)\n",
        "#     self.fc3 = nn.Linear(256,10)\n",
        "    \n",
        "#     self.finalfc=nn.Linear(784,256)\n",
        "   \n",
        "\n",
        "  def forward(self,x):\n",
        "    si=x.size(0)\n",
        "    x1 = F.relu(self.conv_X1(x))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    xinter =x1\n",
        "    \n",
        "    x1 = F.relu(self.conv_X2(x1))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    x1 = F.relu(self.conv_X3(x1))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    \n",
        "    x2 = F.relu(self.conv_Y1(x))\n",
        "    x2 = F.max_pool2d(x2,2,2)\n",
        "    x2 = F.relu(self.conv_Y2(x2))\n",
        "    x2 = F.max_pool2d(x2,2,2)\n",
        "    yinter = x2\n",
        "    x2 = F.relu(self.conv_Y3(x2))\n",
        "    x2= F.max_pool2d(x2,2,2)\n",
        "    \n",
        "    x3 = F.relu(self.conv_Z1(x))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    x3 = F.relu(self.conv_Z2(x3))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    x3 = F.relu(self.conv_Z3(x3))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    zinter=x3\n",
        "    \n",
        "    xinter = F.relu(self.conv_Xinter(xinter))\n",
        "    xinter = F.max_pool2d(xinter,2,2)\n",
        "    yinter = F.relu(self.conv_Yinter(yinter))\n",
        "    yinter = F.max_pool2d(yinter,2,2)\n",
        "    zinter = F.relu(self.conv_Zinter(zinter))\n",
        "    zinter = F.max_pool2d(zinter,2,2)\n",
        "    \n",
        "    xinter = xinter.view(si,-1)\n",
        "    xinter = F.relu(self.fc_Xinter(xinter))\n",
        "    xinter = self.dropout_Xinter(xinter)\n",
        "    \n",
        "    yinter = yinter.view(si,-1)\n",
        "    yinter = F.relu(self.fc_Yinter(yinter))\n",
        "    yinter = self.dropout_Yinter(yinter)\n",
        "    \n",
        "    zinter = zinter.view(si,-1)\n",
        "    zinter = F.relu(self.fc_Zinter(zinter))\n",
        "    zinter = self.dropout_Zinter(zinter)\n",
        "    \n",
        "    \n",
        "    X_end = x1.view(si,-1)\n",
        "    X_end = F.relu(self.fc_Xend(X_end))\n",
        "    X_end = self.dropout_Xend(X_end)\n",
        "    \n",
        "     \n",
        "    Y_end = x2.view(si,-1)\n",
        "    Y_end = F.relu(self.fc_Yend(Y_end))\n",
        "    Y_end = self.dropout_Yend(Y_end)\n",
        "     \n",
        "    Z_end = x3.view(si,-1)\n",
        "    Z_end = F.relu(self.fc_Zend(Z_end))\n",
        "    Z_end = self.dropout_Zend(Z_end)\n",
        "    \n",
        "    flatten=torch.cat((X_end,Y_end,Z_end,xinter,yinter,zinter),dim=1)\n",
        "#     flatten=torch.cat((flatten,zinter),dim=1)\n",
        "#     flatten = F.relu(self.fc1(flatten))\n",
        "#     flatten = self.dropout1(flatten)\n",
        "#     flatten  = F.relu(self.fc2(flatten))\n",
        "#     flatten = self.dropout2(flatten)\n",
        "    \n",
        "    return self.fc1(flatten)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "model = VNetModified().to(device)\n",
        "model    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VNetModified(\n",
              "  (conv_X1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_X2): Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_X3): Conv2d(30, 40, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (conv_Y1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_Y2): Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_Y3): Conv2d(30, 40, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (conv_Z1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_Z2): Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_Z3): Conv2d(30, 40, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (conv_Xinter): Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv_Yinter): Conv2d(30, 40, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (conv_Zinter): Conv2d(40, 50, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (fc_Xinter): Linear(in_features=480, out_features=500, bias=True)\n",
              "  (fc_Yinter): Linear(in_features=40, out_features=100, bias=True)\n",
              "  (fc_Zinter): Linear(in_features=50, out_features=100, bias=True)\n",
              "  (fc_Xend): Linear(in_features=40, out_features=100, bias=True)\n",
              "  (fc_Yend): Linear(in_features=40, out_features=100, bias=True)\n",
              "  (fc_Zend): Linear(in_features=40, out_features=100, bias=True)\n",
              "  (dropout_Xinter): Dropout(p=0.5)\n",
              "  (dropout_Yinter): Dropout(p=0.5)\n",
              "  (dropout_Zinter): Dropout(p=0.5)\n",
              "  (dropout_Xend): Dropout(p=0.5)\n",
              "  (dropout_Yend): Dropout(p=0.5)\n",
              "  (dropout_Zend): Dropout(p=0.5)\n",
              "  (fc1): Linear(in_features=1000, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-0QjKS2e1zP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0p3eZU3h3nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image = torch.randn(2, 1, 28, 28).to(device)\n",
        "# model(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV1S8MRjWTmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVWhJy6GEqIh",
        "colab_type": "text"
      },
      "source": [
        "## RUN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_9YThtmWWPj",
        "colab_type": "code",
        "outputId": "3ed55427-db70-4bad-e51a-0c9dacdbe6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "epochs = 20\n",
        "running_loss_history = []\n",
        "running_corrects_history = []\n",
        "val_running_loss_history = []\n",
        "val_running_corrects_history = []\n",
        "\n",
        "\n",
        "\n",
        "for e in range(epochs):\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0.0\n",
        "  val_running_loss = 0.0\n",
        "  val_running_corrects = 0.0\n",
        "  print(e)\n",
        "  for inputs, labels in training_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    running_loss += loss.item()\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "  else:\n",
        "    with torch.no_grad():\n",
        "      for val_inputs, val_labels in validation_loader:\n",
        "        val_inputs = val_inputs.to(device)\n",
        "        val_labels = val_labels.to(device)\n",
        "        val_outputs = model(val_inputs)\n",
        "        val_loss = criterion(val_outputs, val_labels)\n",
        "        \n",
        "        _, val_preds = torch.max(val_outputs, 1)\n",
        "        val_running_loss += val_loss.item()\n",
        "        val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
        "    epoch_loss = running_loss/len(training_loader)\n",
        "    epoch_acc = running_corrects.float()/ len(training_loader)\n",
        "    running_loss_history.append(epoch_loss)\n",
        "    running_corrects_history.append(epoch_acc)\n",
        "    \n",
        "    val_epoch_loss = val_running_loss/len(validation_loader)\n",
        "    val_epoch_acc = val_running_corrects.float()/ len(validation_loader)\n",
        "    val_running_loss_history.append(val_epoch_loss)\n",
        "    val_running_corrects_history.append(val_epoch_acc)\n",
        "    print('epoch :', (e+1))\n",
        "    print('training loss: {:.4f}, acc {:.4f} '.format(epoch_loss, epoch_acc.item()))\n",
        "    print('validation loss: {:.4f}, validation acc {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "epoch : 1\n",
            "training loss: 0.5942, acc 84.4967 \n",
            "validation loss: 0.1703, validation acc 95.1600 \n",
            "1\n",
            "epoch : 2\n",
            "training loss: 0.1385, acc 95.9367 \n",
            "validation loss: 0.0989, validation acc 96.9900 \n",
            "2\n",
            "epoch : 3\n",
            "training loss: 0.0923, acc 97.2050 \n",
            "validation loss: 0.0694, validation acc 97.8400 \n",
            "3\n",
            "epoch : 4\n",
            "training loss: 0.0719, acc 97.9167 \n",
            "validation loss: 0.0585, validation acc 98.2900 \n",
            "4\n",
            "epoch : 5\n",
            "training loss: 0.0591, acc 98.2283 \n",
            "validation loss: 0.0489, validation acc 98.4800 \n",
            "5\n",
            "epoch : 6\n",
            "training loss: 0.0513, acc 98.4700 \n",
            "validation loss: 0.0424, validation acc 98.7500 \n",
            "6\n",
            "epoch : 7\n",
            "training loss: 0.0438, acc 98.6867 \n",
            "validation loss: 0.0374, validation acc 98.7600 \n",
            "7\n",
            "epoch : 8\n",
            "training loss: 0.0390, acc 98.8317 \n",
            "validation loss: 0.0382, validation acc 98.7800 \n",
            "8\n",
            "epoch : 9\n",
            "training loss: 0.0356, acc 98.9167 \n",
            "validation loss: 0.0322, validation acc 98.9500 \n",
            "9\n",
            "epoch : 10\n",
            "training loss: 0.0312, acc 99.0200 \n",
            "validation loss: 0.0333, validation acc 98.9200 \n",
            "10\n",
            "epoch : 11\n",
            "training loss: 0.0290, acc 99.1167 \n",
            "validation loss: 0.0296, validation acc 99.0200 \n",
            "11\n",
            "epoch : 12\n",
            "training loss: 0.0269, acc 99.1900 \n",
            "validation loss: 0.0275, validation acc 99.0400 \n",
            "12\n",
            "epoch : 13\n",
            "training loss: 0.0238, acc 99.2850 \n",
            "validation loss: 0.0277, validation acc 99.0800 \n",
            "13\n",
            "epoch : 14\n",
            "training loss: 0.0228, acc 99.2850 \n",
            "validation loss: 0.0274, validation acc 99.1000 \n",
            "14\n",
            "epoch : 15\n",
            "training loss: 0.0202, acc 99.3650 \n",
            "validation loss: 0.0267, validation acc 99.1600 \n",
            "15\n",
            "epoch : 16\n",
            "training loss: 0.0177, acc 99.4400 \n",
            "validation loss: 0.0252, validation acc 99.1700 \n",
            "16\n",
            "epoch : 17\n",
            "training loss: 0.0169, acc 99.4767 \n",
            "validation loss: 0.0252, validation acc 99.1300 \n",
            "17\n",
            "epoch : 18\n",
            "training loss: 0.0153, acc 99.5167 \n",
            "validation loss: 0.0289, validation acc 99.0600 \n",
            "18\n",
            "epoch : 19\n",
            "training loss: 0.0143, acc 99.5517 \n",
            "validation loss: 0.0238, validation acc 99.2200 \n",
            "19\n",
            "epoch : 20\n",
            "training loss: 0.0135, acc 99.6150 \n",
            "validation loss: 0.0255, validation acc 99.1600 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV2Ws8L0WvRH",
        "colab_type": "code",
        "outputId": "e0136fe6-7fce-4507-af58-334939a3aecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.plot(running_loss_history, label='training loss')\n",
        "plt.plot(val_running_loss_history, label='validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd3c20a4630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt0XGW9//H3dy6ZyUzuSUvvSdUC\nvdJCuGhFQG4FtAgolANH8KgsOSL608OxeBSE3+IcUA5yUMQDKPDjjgUEpVAEQUARaEspLeVSoLRp\nKU3T5n7PPL8/9iRNSy6TdNLJzHxea82avffs2fubNvnMM3s/+9nmnENERDKLL9UFiIhI8incRUQy\nkMJdRCQDKdxFRDKQwl1EJAMp3EVEMpDCXUQkAyncRUQykMJdRCQDBVK147KyMldRUZGq3YuIpKUV\nK1Zsd86NGWy9lIV7RUUFy5cvT9XuRUTSkpl9kMh6OiwjIpKBFO4iIhlI4S4ikoFSdsxdRPa9jo4O\nqqqqaG1tTXUpMohwOMykSZMIBoPDer/CXSSLVFVVkZ+fT0VFBWaW6nKkH845ampqqKqqYurUqcPa\nhg7LiGSR1tZWSktLFeyjnJlRWlq6V9+wFO4iWUbBnh729v8p7cJ9+YYdXPPEm+j2gCIi/Uu7cF9d\nVcdNz75LTVN7qksRkSGqra3l17/+9bDee/LJJ1NbWzvgOpdddhlPPfXUsLa/p4qKCrZv356UbaVC\n2oV7RVkEgA9qmlNciYgM1UDh3tnZOeB7ly5dSlFR0YDrXHnllRx33HHDri+TpF24TymJAvBBTVOK\nKxGRoVq8eDHvvvsuc+fO5ZJLLuHZZ5/lyCOPZOHChcyYMQOAL33pSxxyyCHMnDmTm2++uee93S3p\nDRs2MH36dL75zW8yc+ZMTjjhBFpaWgA4//zzWbJkSc/6l19+OQcffDCzZ8/mzTffBKC6uprjjz+e\nmTNn8o1vfIPy8vJBW+jXXXcds2bNYtasWVx//fUANDU1ccopp3DQQQcxa9Ys7r///p6fccaMGcyZ\nM4d/+7d/S+4/4BCkXVfIySW5mMEGtdxF9soVf1zLG1vqk7rNGRMKuPyLM/t9/eqrr2bNmjWsWrUK\ngGeffZaVK1eyZs2ani5/v/vd7ygpKaGlpYVDDz2UM844g9LS0t22884773Dvvfdyyy23cOaZZ/Lg\ngw9y7rnnfmx/ZWVlrFy5kl//+tdce+213HrrrVxxxRV8/vOf59JLL+WJJ57gt7/97YA/04oVK7jt\nttt46aWXcM5x+OGHc9RRR/Hee+8xYcIEHnvsMQDq6uqoqanh4Ycf5s0338TMBj2MNJLSruUeCviZ\nUJjLRrXcRTLCYYcdtltf7htuuIGDDjqII444gk2bNvHOO+987D1Tp05l7ty5ABxyyCFs2LChz22f\nfvrpH1vnhRdeYNGiRQAsWLCA4uLiAet74YUXOO2004hGo+Tl5XH66afz/PPPM3v2bP785z/zwx/+\nkOeff57CwkIKCwsJh8N8/etf56GHHiISiQz1nyNp0q7lDlBeGlHLXWQvDdTC3pei0WjP9LPPPstT\nTz3Fiy++SCQS4eijj+6zr3coFOqZ9vv9PYdl+lvP7/cPekx/qPbff39WrlzJ0qVL+fGPf8yxxx7L\nZZddxssvv8zTTz/NkiVL+NWvfsVf/vKXpO43UQm13M1sgZm9ZWbrzWxxP+ucaWZvmNlaM7snuWXu\nrrw0wsYdCneRdJOfn09DQ0O/r9fV1VFcXEwkEuHNN9/kH//4R9JrmD9/Pg888AAATz75JDt37hxw\n/SOPPJI//OEPNDc309TUxMMPP8yRRx7Jli1biEQinHvuuVxyySWsXLmSxsZG6urqOPnkk/nFL37B\na6+9lvT6EzVoy93M/MCNwPFAFfCKmT3qnHuj1zrTgEuB+c65nWY2dqQKBigvjbKjqZ361g4KwsMb\nd0FE9r3S0lLmz5/PrFmzOOmkkzjllFN2e33BggX85je/Yfr06RxwwAEcccQRSa/h8ssv5+yzz+bO\nO+/k05/+NOPGjSM/P7/f9Q8++GDOP/98DjvsMAC+8Y1vMG/ePJYtW8Yll1yCz+cjGAxy00030dDQ\nwKmnnkprayvOOa677rqk158oG+xiIDP7NPBT59yJ8flLAZxz/9VrnZ8Bbzvnbk10x5WVlW64N+t4\n/PUPufDulfzpO59l1sTCYW1DJButW7eO6dOnp7qMlGpra8Pv9xMIBHjxxRe58MILe07wjjZ9/X+Z\n2QrnXOVg703kmPtEYFOv+Srg8D3W2T++078BfrwPgyf23JCZXQBcADBlypQEdt238lLvGN2GmiaF\nu4gMycaNGznzzDOJxWLk5ORwyy23pLqkEZGsE6oBYBpwNDAJeM7MZjvndusH5Jy7GbgZvJb7cHdW\nXqoLmURkeKZNm8arr76a6jJGXCInVDcDk3vNT4ov660KeNQ51+Gcex94Gy/sR0Q0FKAsL6QLmURE\n+pFIuL8CTDOzqWaWAywCHt1jnT/gtdoxszK8wzTvJbHOj6lQd0gRkX4NGu7OuU7gImAZsA54wDm3\n1syuNLOF8dWWATVm9gbwDHCJc65mpIoGmFIaYaPCXUSkTwkdc3fOLQWW7rHssl7TDvh+/LFPVJRG\neWjlZlo7uggH/ftqtyIiaSHthh/o1n1SVRcziWS2vLw8ALZs2cKXv/zlPtc5+uijGaxr9fXXX09z\n8668SGQI4UT89Kc/5dprr93r7SRbGod7vDvkdp1UFckGEyZM6BnxcTj2DPdEhhBOZ+kb7iVquYuk\nm8WLF3PjjTf2zHe3ehsbGzn22GN7hud95JFHPvbeDRs2MGvWLABaWlpYtGgR06dP57TTTtttbJkL\nL7yQyspKZs6cyeWXXw54g5Ft2bKFY445hmOOOQbY/WYcfQ3pO9DQwv1ZtWoVRxxxBHPmzOG0007r\nGdrghhtu6BkGuHvQsr/+9a/MnTuXuXPnMm/evAGHZRiOtBw4DKAoEqQgHGCDukOKDM/ji2Hr68nd\n5rjZcNLV/b581lln8b3vfY9vf/vbADzwwAMsW7aMcDjMww8/TEFBAdu3b+eII45g4cKF/d5H9Kab\nbiISibBu3TpWr17NwQcf3PPaVVddRUlJCV1dXRx77LGsXr2aiy++mOuuu45nnnmGsrKy3bbV35C+\nxcXFCQ8t3O2rX/0qv/zlLznqqKO47LLLuOKKK7j++uu5+uqref/99wmFQj2Hgq699lpuvPFG5s+f\nT2NjI+FwOOF/5kSkbcvdzKgoi+pCJpE0Mm/ePLZt28aWLVt47bXXKC4uZvLkyTjn+NGPfsScOXM4\n7rjj2Lx5Mx999FG/23nuued6QnbOnDnMmTOn57UHHniAgw8+mHnz5rF27VreeOON/jYD9D+kLyQ+\ntDB4g57V1tZy1FFHAXDeeefx3HPP9dR4zjnncNdddxEIeG3q+fPn8/3vf58bbriB2tranuXJkrYt\nd4ApJRFWV9WlugyR9DRAC3skfeUrX2HJkiVs3bqVs846C4C7776b6upqVqxYQTAYpKKios+hfgfz\n/vvvc+211/LKK69QXFzM+eefP6ztdEt0aOHBPPbYYzz33HP88Y9/5KqrruL1119n8eLFnHLKKSxd\nupT58+ezbNkyDjzwwGHXuqe0bbmD1x1yc20LHV2xVJciIgk666yzuO+++1iyZAlf+cpXAK/VO3bs\nWILBIM888wwffPDBgNv43Oc+xz33eCOLr1mzhtWrVwNQX19PNBqlsLCQjz76iMcff7znPf0NN9zf\nkL5DVVhYSHFxcU+r/8477+Soo44iFouxadMmjjnmGK655hrq6upobGzk3XffZfbs2fzwhz/k0EMP\n7bkNYLKkd8u9NEJXzLF5ZwsVZdHB3yAiKTdz5kwaGhqYOHEi48ePB+Ccc87hi1/8IrNnz6aysnLQ\nFuyFF17I1772NaZPn8706dM55JBDADjooIOYN28eBx54IJMnT2b+/Pk977ngggtYsGABEyZM4Jln\nnulZ3t+QvgMdgunPHXfcwbe+9S2am5v5xCc+wW233UZXVxfnnnsudXV1OOe4+OKLKSoq4ic/+QnP\nPPMMPp+PmTNnctJJJw15fwMZdMjfkbI3Q/52e/n9HZz5vy9y+9cO5egDRnQIeZGMoCF/08veDPmb\n1odldCGTiEjf0jrcx+aHCAd9bNiucBcR6S2tw93MKC+JsnGH+rqLJCpVh2JlaPb2/ymtwx28QzMa\n+lckMeFwmJqaGgX8KOeco6amZq8ubErr3jIAFWVRnn27mljM4fP1fTWbiHgmTZpEVVUV1dXVqS5F\nBhEOh5k0adKw35/24T6lJEJ7Z4yt9a1MKMpNdTkio1owGGTq1KmpLkP2gbQ/LFMRHx1SwxCIiOyS\n9uG+62bZOqkqItIt7cN9fGGYoN90UlVEpJe0D/eA38ek4oi6Q4qI9JL24Q7x7pC6kElEpEdmhHtJ\nhI07mtV3V0QkLjPCvTRKY1snNU3tqS5FRGRUyIhwryjr7jGjQzMiIpBguJvZAjN7y8zWm9niPl4/\n38yqzWxV/PGN5Jfavykl3X3ddVJVRAQSuELVzPzAjcDxQBXwipk96pzb88aE9zvnLhqBGgc1uSQX\nM7XcRUS6JdJyPwxY75x7zznXDtwHnDqyZQ1NKOBnQmGuWu4iInGJhPtEYFOv+ar4sj2dYWarzWyJ\nmU1OSnVDoNEhRUR2SdYJ1T8CFc65OcCfgTv6WsnMLjCz5Wa2PNmj0pWXRnRHJhGRuETCfTPQuyU+\nKb6sh3OuxjnXFp+9FTikrw055252zlU65yrHjBkznHr7VV4aZUdTO/WtHUndrohIOkok3F8BppnZ\nVDPLARYBj/ZewczG95pdCKxLXomJKS+J309Vh2ZERAYPd+dcJ3ARsAwvtB9wzq01syvNbGF8tYvN\nbK2ZvQZcDJw/UgX3pzw+9O8GnVQVEUnsZh3OuaXA0j2WXdZr+lLg0uSWNjRTSnUhk4hIt4y4QhUg\nLxSgLC+k7pAiImRQuANUlEbUchcRIcPCfYrCXUQEyLBwryiNsrW+ldaOrlSXIiKSUhkV7t33U9XF\nTCKS7TIs3OPdIbfrpKqIZLfMCvcStdxFRCDDwr0oEqQgHNCFTCKS9TIq3M2M8tKoesyISNbLqHAH\n76Sqwl1Esl3GhXtFaZTNtS10dMVSXYqISMpkXLhPKY3QFXNs3tmS6lJERFIm48K9QqNDiohkXrjr\nQiYRkQwM97H5IcJBHxu2K9xFJHtlXLibGeUlUTbu0GEZEcleGRfu4B2a2aDukCKSxTI23DfuaCYW\nc6kuRUQkJTI03KO0d8bYWt+a6lJERFIiI8O9uzukrlQVkWyVkeFe3nOzbJ1UFZHslJHhPr4wTNBv\nfKC+7iKSpTIy3AN+H5OKI2q5i0jWyshwh3h3SF3IJCJZKqFwN7MFZvaWma03s8UDrHeGmTkzq0xe\nicNTXuJ1h3RO3SFFJPsMGu5m5gduBE4CZgBnm9mMPtbLB74LvJTsIoejvDRKY1snNU3tqS5FRGSf\nS6Tlfhiw3jn3nnOuHbgPOLWP9f4vcA0wKjqX7+oxo0MzIpJ9Egn3icCmXvNV8WU9zOxgYLJz7rGB\nNmRmF5jZcjNbXl1dPeRih6K8p6+7TqqKSPbZ6xOqZuYDrgN+MNi6zrmbnXOVzrnKMWPG7O2uBzS5\nJBcztdxFJDslEu6bgcm95ifFl3XLB2YBz5rZBuAI4NFUn1QNBfxMKMxVy11EslIi4f4KMM3MpppZ\nDrAIeLT7RedcnXOuzDlX4ZyrAP4BLHTOLR+RioegvDSiC5lEJCsNGu7OuU7gImAZsA54wDm31syu\nNLOFI13g3igvjeiwjIhkpUAiKznnlgJL91h2WT/rHr33ZSVHeWmUHU3t1Ld2UBAOprocEZF9JmOv\nUAXvQiaAjWq9i0iWyexwj3eH3KCTqiKSZTI63KfoQiYRyVIZHe55oQBleSF1hxSRrJPR4Q7qMSMi\n2UnhLiKSgTI+3CtKo2ytb6W1oyvVpYiI7DMZH+7do0Nu1JWqIpJFsiDc490ht+ukqohkj8wP9xK1\n3EUk+2R8uBdFghSEA7qQSUSySsaHu5lRXhpVjxkRySoZH+6g7pAikn2yJtw317bQ0RVLdSkiIvtE\nloR7lK6YY/POllSXIiKyT2RFuFd03yxbPWZEJEtkRbiX94wOqR4zIpIdsiLcx+aHCAd9bNiulruI\nZIesCHczo7wkysYdarmLSHbIinAH79DMBnWHFJEskVXhvnFHM7GYS3UpIiIjLovCPUp7Z4yt9a2p\nLkVEZMRlUbjrfqoikj0SCnczW2Bmb5nZejNb3Mfr3zKz181slZm9YGYzkl/q3unp667ukCKSBQYN\ndzPzAzcCJwEzgLP7CO97nHOznXNzgZ8B1yW90r00vjBM0G+6kElEskIiLffDgPXOufecc+3AfcCp\nvVdwztX3mo0Co+6sZcDvY1JxRC13EckKgQTWmQhs6jVfBRy+50pm9m3g+0AO8PmkVJdk5aURXcgk\nIlkhaSdUnXM3Ouc+CfwQ+HFf65jZBWa23MyWV1dXJ2vXCSsv8bpDOjfqvliIiCRVIuG+GZjca35S\nfFl/7gO+1NcLzrmbnXOVzrnKMWPGJF5lkpSXRmls66SmqX2f71tEZF9KJNxfAaaZ2VQzywEWAY/2\nXsHMpvWaPQV4J3klJo+6Q4pIthg03J1zncBFwDJgHfCAc26tmV1pZgvjq11kZmvNbBXecffzRqzi\nvVCu7pAikiUSOaGKc24psHSPZZf1mv5ukusaEZNLcjFTy11EMl/WXKEKEAr4mVCYq5a7iGS8rAp3\ngCklEV3IJCIZL+vCvaIsosMyIpLxsi7cy0uj7Ghqp761I9WliIiMmOwL9xKvO+RGtd5FJINlX7jH\nu0Nu0ElVEclgWRfuU3Qhk4hkgawL97xQgLK8kLpDikhGy7pwB28YArXcRSSTKdxFRDJQdoZ7SZSt\n9a20dnSluhQRkRGRleFeURbvDqkrVUUkQ2VluO8aHVLhLiKZKTvDvaS7O6R6zIhIZsrKcC+KBCkI\nB3Qhk4hkrKwMdzOjvDSqwzIikrGyMtxB3SFFJLNldbhvrm2hoyuW6lJERJIui8M9SlfMsXlnS6pL\nERFJuuwN9+4eM+rrLiIZKGvDvaKsu6+7esyISObJ2nAfmx8iHPTppKqIZKSsDXczo7wkqpa7iGSk\nrA138HrMbFDLXUQyUELhbmYLzOwtM1tvZov7eP37ZvaGma02s6fNrDz5pSZfeWmEjTuaicVcqksR\nEUmqQcPdzPzAjcBJwAzgbDObscdqrwKVzrk5wBLgZ8kudCSUl0Zp74yxtb411aWIiCRVIi33w4D1\nzrn3nHPtwH3Aqb1XcM4945zrPr7xD2BScsscGeW6n6qIZKhEwn0isKnXfFV8WX++Djze1wtmdoGZ\nLTez5dXV1YlXOUIqStUdUkQyU1JPqJrZuUAl8PO+XnfO3eycq3TOVY4ZMyaZux6W8YVhAj7ThUwi\nknECCayzGZjca35SfNluzOw44D+Ao5xzbckpb2QF/D4ml0TUcheRjJNIy/0VYJqZTTWzHGAR8Gjv\nFcxsHvC/wELn3LbklzlyNDqkiGSiQcPdOdcJXAQsA9YBDzjn1prZlWa2ML7az4E84PdmtsrMHu1n\nc6NOeYkX7s6pO6SIZI5EDsvgnFsKLN1j2WW9po9Lcl37THlplMa2Tmqa2inLC6W6HBGRpEi/K1S7\nOmDjP5K2OXWHFJFMlH7h/uzVcPsXYP3TSdlcubpDikgGSr9w/8x3YMwBcP8/Q9WKvd7c5JJczNRy\nF5HMkn7hnlsE5z4I0TK4+8uw/Z292lwo4GdCYa5a7iKSUdIv3AHyx8E/PwzmgztPg/ote7W5KSUR\nXcgkIhklPcMdoPSTcO4SaNkJd53hPQ9TRZn6uotIZknfcAeYMA8W3Q016+GeRdA+vICeUhJlR1M7\n9a0dSS5QRCQ10jvcAT5xNJx+M2x6CZZ8Dbo6h7yJinh3yI1qvYtIhkj/cAeYeRqc/HN4+wn443dh\niFebdneH3KCTqiKSIRK6QjUtHPZNaKqGv17j9aQ5/oqE3zpFFzKJSIbJnHAHOPpSaNwGf7se8sbC\np7+d0NvyQgHK8kLqDikiGSOzwt0MTvlvaK6BZT+CSBkcdFZCb60ojfDiezVs2tHM5JLICBcqIjKy\nMuOYe28+P5x+C1QcCY/8K7zz54TedvGx06ht6uDkG57niTUfjnCRIiIjK/PCHSAYhkX3wNjp8MBX\noWr5oG/53P5jeOziI/lEWZRv3bWSyx5ZQ2tH1z4oVkQk+TIz3AHCBXDOg96x97u/DNVvDfqWKaUR\nfv+tz/DNI6fy/178gNN//Xfeq27cB8WKiCRX5oY7QP5+3jAFviDceTrUVQ36lpyAj/84ZQa/Pa+S\nLXUtfPGXL/CHVz92V0ERkVEts8MdoOQT3jAFrXXeMAXNOxJ627HT9+Px7x7JzAmFfO/+VVzy+9do\nbh/6BVIiIqmQ+eEOMP4gOPse2PEe3HNWwsMUjC/M5Z5vHs53Pv8plqysYuGv/sZbWxtGuFgRkb2X\nHeEOMPVzcMatUPUK/P48745OCQj4ffzghAO46+uHU9vcwcJfvcC9L2/UPVdFZFTLnnAHmHEqfOE6\neOdJePQ7EIsl/Nb5nyrj8e8eyWFTS7j0ode5+L5VNGigMREZpbIr3AEq/wWO/hG8di88dfmQ3jom\nP8QdXzuMS048gKWvf8gXfvkCr1fVjVChIiLDl33hDnDUv8Oh34S/3wB//+WQ3urzGd8+5lPcf8ER\ntHfGOP2mv3Hb397XYRoRGVWyM9zN4KRrYMaX4Mkfw6p7h7yJyooSll58JEftP4Yr/vgGF9y5gtrm\n9hEoVkRk6BIKdzNbYGZvmdl6M1vcx+ufM7OVZtZpZl9OfpkjwOf3xoGfehQ88m14+8khb6I4msMt\nX63kJ1+YwbNvbePk/3meFR8k1tVSRGQkDRruZuYHbgROAmYAZ5vZjD1W2wicD9yT7AJHVCDk3clp\n3GxvmIL3nx/yJsyMr392Kg9e+BkCfh9n/u8/+PWz64nFdJhGRFInkZb7YcB659x7zrl24D7g1N4r\nOOc2OOdWA4l3PxktQvlwzhIomAB3fAFuPR5evXvIt+ybM6mIP138WRbMGsfPnniL8257meqGthEq\nWkRkYImE+0RgU6/5qviyzJE3Br75NJxwlXej7Uf+Ff77QHjsB7D19YQ3UxAO8quz5/Gfp83m5fd3\ncPINz/P39dtHsHARkb7t0xOqZnaBmS03s+XV1dX7cteDyy2Gz1wEF70C5y+FAxbAyjvhN5+FWz4P\nK+6AtsEHETMz/unwKTxy0XwKwgHO+e1L/OvdK3j0tS00tmn4AhHZN2ywLnxm9mngp865E+PzlwI4\n5/6rj3VvB/7knFsy2I4rKyvd8uWDD8WbUs07YPX9sOJ2qH4TcvJg9lfgkPNhwtzB397eyXVPvs0f\nVm1he2MbOQEfn5tWxokzx3H8jP0oiuSM+I8gIpnFzFY45yoHXS+BcA8AbwPHApuBV4B/cs6t7WPd\n28mkcO/mHGx62Qv5tQ9BZ6s3Xs0h58OsL3vDCw+gK+ZY8cFOnlizlSfWfMiWulYCPuPTnyzlxJnj\nOGHmfozND++TH0VE0lvSwj2+sZOB6wE/8Dvn3FVmdiWw3Dn3qJkdCjwMFAOtwFbn3MyBtplW4d5b\nSy28/ntYfhtsWwvBKMw+I96aP9jrQz8A5xyrq+p4Yu1Wnlizlfe3N2EGh5aXcOKscSyYNY6JRbn7\n5mcRkbST1HAfCWkb7t2cg80rYMVtsOYh6GiG/WbDIefBnDMhXJjAJhxvfdQQb9Fv5c34iJMHTSrk\nxFnjOGnWeKaWRUf6JxGRNKJw35da673W/IrbYetqCOTCrNO91vykQwdtzXd7f3tTz6Gb1+Jj1hw4\nLp8TZ47jpNnjOGC/fCzBbYlIZlK4p8qWV72Qf30JtDfC2Bkw6wzYfwHsNzPhoN9c28KyeIv+lQ92\n4BxMLYuyYNY4Fswcx5xJhQp6kSykcE+1tgZY8yC8epc3hjxA4WTY/0Qv6CuO9G7knYDqhjaefMML\n+hffraEz5phQGOawqSXMm1LM3MlFTB9fQE4gO4cKEskmCvfRpGGrN4b828vg3b94x+eDEfjE0V7Q\nTzsBCsYntKna5naeWreNp9d9xIoPdrItfhVsTsDH7ImFzJtcxLwpxcybUsT4wrBa9yIZRuE+WnW0\nwoYX4O0nvEdd/OLf8XO9oN//RG/aN3gr3DnHh3WtrNpUy6sbd/Lqxlpe31xHW6c3CsR+BSHmTfaC\nft6UYmZPLCQ3xz+SP52IjDCFezpwDratg7cf91r1m14GHOSNg/1P8ML+E0dDTuI9Zto7Y7y5tZ5X\nN8YDf1MtH9R44+T4fcaB4/K9sI+H/tSyqFr3ImlE4Z6OmrbD+qfgrce9wzdt9eAPefd/3f9E71E0\nZcibrWlsY9Wm2ngL33vuHgqhKBJk7uQi5k7e1bovjgQV+CKjlMI93XW2w8YXvRb924/Djve85WNn\neiH/qeOgcKLXnz5U4I1Pn6CumOPd6saeQzmvbqzl7W0NdP8qRHP8TCqOMLE4l4lFuUwqzu01HaEs\nL0fhL5IiCvdM4hzUrPeO0b/1hBf6rmv3dUIFXtAP6VHU8+HQ0N7F61V1vPFhPVU7W9hc2+I972ym\nvnX3Ac9CAR8Ti7zAn9Qr9Ls/APYrCOP3KfxFRoLCPZO17ISNL0FzDbTWDf5oG+wm3rbrwyG3EKJj\ndnu05JRQ7Qr4sCOfje1R3m0Ks7G+i807vQ+Amqbdby8Y8Bnji8K7Qr8olwlFYfYr2PXQoR+R4Uk0\n3AP7ohhJstxib0jiRMW6vH73iXwQtOyApmrvm0JjNXS2kAtMiT8O795mqBCiZTBhDF2RMhoDxey0\nQrbFCtjSkccHrVHebc5l1dshHmwM4NzuQZ7j9zEmP8S4wjD7FYQYm98d/CHGFYQZG5/OCwX0ISAy\nDAr3bODzQ26R9xiq9iZo3Oad7G2qhqZt8ef4fOM2/DvepbCpmsLmGir4+DdBlxskFi6mPaeQFn8B\nDZZPHVF2xCJsa47wYW2YqtYr3oAEAAAK4ElEQVQwf+/Ipc5FqSWPWhelgQi5OcGe0O9u9Y/N3zVd\nEg1SkBukIBwkHFQ3T5FuCncZWE4USqZ6j8HEurxDRU3Vuz4AGrdhTdvwN+8gt7WW3JadlLTUQMu7\n3uGl9vgNUAzYY3h7h9Hiz6epLY+66jxqtkbZ1pnLjliU94myyuVR4wqoppDtrpB6fzEuXExeJExh\nbpDC3CAF4cCu6fijMP5h4C3zXtc3BMk0CndJHp8f8sZ6j0R1tkNrrTeUcsvO3R7WspNIy04irbWM\nadnJp1p24lq24pp3Yq21WB/fEmKdPhqaCqltKaKGIqpjBWztKmBzZz6bYoVsj38QbHeF1FBALH4z\nMp/RE/x9PYoi3dM5H1sWyfHrg0FGHYW7pFYgZ0gfCBZ/EIt5J4rj3w5o2gaN1fiatlHY+BGFjdWU\nN22Dxve912j92LYcRltOMc3BEhoCxdT6ithBMds782nY6aPhI6Ohw9jeYWyO+egkQAd+OgjQQYBO\n/HQ4P84fJBwKEQqFiYTD5OaGiYRzyYvkEo14z/mRXAoiuRRGc3b70NChJBkpCndJTz6fd2I5txjK\npg28rnPeCeX4OQIaP4KmaqxxG+GmbYQbqylp2kZ549veOh3Nu78/kb+SLqA5/uhHzBltBGklh1Zy\n+NAFabMQnb4QXb4QMX+YWCAMgTAWzMVycvHn5BIIRQiGIoRyo4RyI4Rz88iNRMkJRyEQH3yuq927\nQ1hnW/wRn+7qPd++x/K+lsWXd3V4t5WMlkGkBCKl8UdZ/Dm+LBqfD+oGM6ONwl0yn5l3K8RwAZR+\ncvD125u9oOvqhFiHF5x7Tne1x+fjj49Ne+vFutppa2ulra2NttYW2lub6Wxrpqu9hVh7C76OFnI6\nW7DOVnxd9fjbthFsaSPo2gm5NsJ0ELKOvf4n6LIAMV8Ozh/CBUI4fwgLhLFgCAuG8QfDWLgAC4S8\nq6L9OdDeAE01sO1N71xKyw5wsb53EIz0Cv2yXh8GpRDtNR0uApx3fibW5V2v0dfzUJdh3rdAfwgC\n3Y+w93N0z/d+bbfpnISH4k4nCneRPeVEgEhSNuUDcuOPoeqKORpaO/iwqY36xkYaGxtoamqkuamR\nluYm2loaaWtppqmji8ZOH/WdAeo7fNR3+Klt91HX4WNnu9Hmgj3nFgYS8BmRHD/RUIBoKEBu0E9u\n0E844ie30Ec06KPI10Kp1VNMPYWunnxXT35XHdGuOiKdtYQ7agnXbSe47R0CbTvxtzcM4ydPgf6C\n33zeN7/u8zvd0wk/0/fy434KBy0a0R9J4S4ySvl9RlEkh6JIDozJBxIbFrq3WMzR2tlFU1sXTW2d\nNLV30twen27r8ubbOmmKL+t5rb2TlvYuWjq6qGvp4KM6b7qlo4vWdh/NHfl0xfKACQPuP0gnRTRQ\nag0UWwOlvmYCAR9+fxCf308gEMDnDxAIBPD7AwQCQQKBQM8jGAh6y4JBgoEAOcEgwWD3c5CcYA45\nwQAhv5Hj6yREByHrJMd1kEMHQdoJuk4Crp1ArB3rPnzV+zBWz3Tv1+KHp5zb1aq3njM+u6aH/Iz3\nXDBxyP+XQ6VwF8lgPp8RyQkQyQkwJj+U1G23d8a8sO/o6vkg8MJ/13RLe/z1ji5a2mM0d3TS1hGj\nrbOLto4YTfHn1u7nji7amveY74zR1tkBdAAtw67XLIccf5icQBGhgI8cv4+cQK9Hz7yfHL+PUMBH\nKOgj3P0NJuiLP/t7LfOTm+PbbVlur+lQ0NtOKnpTKdxFZFi6Q7EwNzji+3LOeSEf/2Bo3eO5rTNG\ne+fu0+1d8ec95tsGeK29M0ZdS0d8etf2uz+8YsMYrcWMjwX+947bn4UHDfytZ28p3EVk1DOzntYx\njPyHSV+cc3R0OVo6umjr/pbSEdv1DaXT+9bS2ul9S+n+VtP96P720trZRXFk5H8GhbuISALMjJyA\nefcq3gffVvaW7qgsIpKBEgp3M1tgZm+Z2XozW9zH6yEzuz/++ktmVpHsQkVEJHGDhruZ+YEbgZOA\nGcDZZjZjj9W+Dux0zn0K+AVwTbILFRGRxCXScj8MWO+ce8851w7cB5y6xzqnAnfEp5cAx5pGUhIR\nSZlEwn0isKnXfFV8WZ/rOOc6gTqgdM8NmdkFZrbczJZXV1cPr2IRERnUPj2h6py72TlX6ZyrHDNm\nzL7ctYhIVkkk3DcDk3vNT4ov63MdMwsAhUBNMgoUEZGhSyTcXwGmmdlUM8sBFgGP7rHOo8B58ekv\nA39xqbrztoiIYIlksJmdDFwP+IHfOeeuMrMrgeXOuUfNLAzcCcwDdgCLnHPvDbLNauCDYdZdBmwf\n5ntTIZ3qTadaIb3qTadaIb3qTadaYe/qLXfODXpcO6FwH23MbLlzrjLVdSQqnepNp1ohvepNp1oh\nvepNp1ph39SrK1RFRDKQwl1EJAOla7jfnOoChiid6k2nWiG96k2nWiG96k2nWmEf1JuWx9xFRGRg\n6dpyFxGRAaRduA82QuVoYWaTzewZM3vDzNaa2XdTXVMizMxvZq+a2Z9SXctAzKzIzJaY2Ztmts7M\nPp3qmgZiZv8n/nuwxszujXcfHjXM7Hdmts3M1vRaVmJmfzazd+LPxamssVs/tf48/ruw2sweNrOi\nVNbYra9ae732AzNzZlY2EvtOq3BPcITK0aIT+IFzbgZwBPDtUVxrb98F1qW6iAT8D/CEc+5A4CBG\ncc1mNhG4GKh0zs3Cu15kUWqr+pjbgQV7LFsMPO2cmwY8HZ8fDW7n47X+GZjlnJsDvA1cuq+L6sft\nfLxWzGwycAKwcaR2nFbhTmIjVI4KzrkPnXMr49MNeOEz8rc83wtmNgk4Bbg11bUMxMwKgc8BvwVw\nzrU752pTW9WgAkBufHiOCLAlxfXsxjn3HN4FiL31Hu31DuBL+7SofvRVq3PuyfighQD/wBsmJeX6\n+XcFb2j0fwdG7KRnuoV7IiNUjjrxm5fMA15KbSWDuh7vFy6W6kIGMRWoBm6LH0K61cyiqS6qP865\nzcC1eK20D4E659yTqa0qIfs55z6MT28F9ktlMUPwL8DjqS6iP2Z2KrDZOffaSO4n3cI97ZhZHvAg\n8D3nXH2q6+mPmX0B2OacW5HqWhIQAA4GbnLOzQOaGD2HDD4mfqz6VLwPpQlA1MzOTW1VQxMfK2rU\nd60zs//AOyR6d6pr6YuZRYAfAZeN9L7SLdwTGaFy1DCzIF6w3+2ceyjV9QxiPrDQzDbgHe76vJnd\nldqS+lUFVDnnur8JLcEL+9HqOOB951y1c64DeAj4TIprSsRHZjYeIP68LcX1DMjMzge+AJwzigcu\n/CTeh/xr8b+1ScBKMxuX7B2lW7gnMkLlqBC/E9VvgXXOuetSXc9gnHOXOucmOecq8P5d/+KcG5Wt\nS+fcVmCTmR0QX3Qs8EYKSxrMRuAIM4vEfy+OZRSfAO6l92iv5wGPpLCWAZnZArxDigudc82prqc/\nzrnXnXNjnXMV8b+1KuDg+O90UqVVuMdPmFwELMP743jAObc2tVX1az7wz3gt4FXxx8mpLiqDfAe4\n28xWA3OB/0xxPf2Kf8NYAqwEXsf7uxtVV1Sa2b3Ai8ABZlZlZl8HrgaON7N38L59XJ3KGrv1U+uv\ngHzgz/G/td+ktMi4fmrdN/sevd9eRERkuNKq5S4iIolRuIuIZCCFu4hIBlK4i4hkIIW7iEgGUriL\niGQghbuISAZSuIuIZKD/D+QkXnRz44O4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyWyoh22Wydn",
        "colab_type": "code",
        "outputId": "8dec58f6-3016-45e2-c71b-6721aba08ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "\n",
        "plt.plot(running_corrects_history, label='training accuracy')\n",
        "plt.plot(val_running_corrects_history, label='validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd3c656cfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGJclBGOMMYAlBGOMMS5LCMYYYwD4/9hC7UfiRyQSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KSTfQd7DpP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LZkY22SDpqd",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGK1_peJDsmd",
        "colab_type": "code",
        "outputId": "c94632b1-3fd6-4673-88f9-72b3561d007f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "transform_train = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomRotation(10),\n",
        "                                      transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "                                      transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                               ])\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((32,32)),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                               ])\n",
        "training_dataset = datasets.CIFAR10(root='./d', train=True, download=True, transform=transform_train)\n",
        "validation_dataset = datasets.CIFAR10(root='./dq', train=False, download=True, transform=transform)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./d/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 169730048/170498071 [00:10<00:00, 20896489.02it/s]\n",
            "0it [00:00, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dq/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/170498071 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 8192/170498071 [00:00<50:32, 56219.70it/s]\u001b[A\n",
            "  0%|          | 40960/170498071 [00:00<39:10, 72517.69it/s]\u001b[A\n",
            "  0%|          | 106496/170498071 [00:01<29:18, 96883.81it/s]\u001b[A\n",
            "  0%|          | 221184/170498071 [00:01<21:35, 131462.21it/s]\u001b[A\n",
            "  0%|          | 450560/170498071 [00:01<15:37, 181307.14it/s]\u001b[A\n",
            "  0%|          | 729088/170498071 [00:01<11:22, 248878.05it/s]\u001b[A\n",
            "  1%|          | 1482752/170498071 [00:01<08:05, 348342.05it/s]\u001b[A\n",
            "  2%|         | 2793472/170498071 [00:01<05:42, 489288.52it/s]\u001b[A\n",
            "  3%|         | 5431296/170498071 [00:01<03:58, 690663.22it/s]\u001b[A\n",
            "  5%|         | 8298496/170498071 [00:02<02:46, 971280.36it/s]\u001b[A\n",
            "  6%|         | 11051008/170498071 [00:02<01:57, 1357547.39it/s]\u001b[A\n",
            "  8%|         | 14180352/170498071 [00:02<01:22, 1888187.81it/s]\u001b[A\n",
            " 10%|         | 17309696/170498071 [00:02<00:58, 2599302.46it/s]\u001b[A\n",
            " 12%|        | 20094976/170498071 [00:02<00:43, 3495832.01it/s]\u001b[A\n",
            " 14%|        | 23142400/170498071 [00:02<00:31, 4653333.69it/s]\u001b[A\n",
            " 15%|        | 26288128/170498071 [00:02<00:23, 6057551.49it/s]\u001b[A\n",
            " 17%|        | 29417472/170498071 [00:03<00:18, 7719638.94it/s]\u001b[A\n",
            " 19%|        | 32235520/170498071 [00:03<00:14, 9318454.80it/s]\u001b[A\n",
            " 21%|        | 35364864/170498071 [00:03<00:12, 11220576.97it/s]\u001b[A\n",
            " 23%|       | 38510592/170498071 [00:03<00:10, 13045666.06it/s]\u001b[A\n",
            " 24%|       | 41295872/170498071 [00:03<00:08, 14357819.65it/s]\u001b[A\n",
            " 26%|       | 44425216/170498071 [00:03<00:07, 15830532.06it/s]\u001b[A\n",
            " 28%|       | 47505408/170498071 [00:04<00:07, 17116784.59it/s]\u001b[A\n",
            " 30%|       | 50634752/170498071 [00:04<00:06, 18352846.01it/s]\u001b[A\n",
            " 31%|      | 53469184/170498071 [00:04<00:06, 18369150.35it/s]\u001b[A\n",
            " 33%|      | 56598528/170498071 [00:04<00:05, 19190609.73it/s]\u001b[A\n",
            " 35%|      | 59727872/170498071 [00:04<00:05, 19812113.52it/s]\u001b[A\n",
            " 37%|      | 62513152/170498071 [00:04<00:05, 19384880.10it/s]\u001b[A\n",
            " 39%|      | 65642496/170498071 [00:04<00:05, 19253811.38it/s]\u001b[A\n",
            " 40%|      | 68788224/170498071 [00:05<00:05, 19790881.28it/s]\u001b[A\n",
            " 42%|     | 71917568/170498071 [00:05<00:04, 20359750.23it/s]\u001b[A\n",
            " 44%|     | 75046912/170498071 [00:05<00:04, 21503174.31it/s]\u001b[A\n",
            " 46%|     | 77864960/170498071 [00:05<00:04, 19659789.91it/s]\u001b[A\n",
            " 48%|     | 80994304/170498071 [00:05<00:04, 20045065.13it/s]\u001b[A\n",
            " 49%|     | 83927040/170498071 [00:05<00:04, 19892072.29it/s]\u001b[A\n",
            " 51%|     | 87056384/170498071 [00:05<00:04, 20204081.83it/s]\u001b[A\n",
            " 53%|    | 90202112/170498071 [00:06<00:03, 20375574.11it/s]\u001b[A\n",
            " 55%|    | 93331456/170498071 [00:06<00:03, 20681320.37it/s]\u001b[A\n",
            " 56%|    | 96149504/170498071 [00:06<00:03, 20056382.83it/s]\u001b[A\n",
            " 58%|    | 99278848/170498071 [00:06<00:03, 20267765.11it/s]\u001b[A\n",
            " 60%|    | 102408192/170498071 [00:06<00:03, 20609188.82it/s]\u001b[A\n",
            " 62%|   | 105553920/170498071 [00:06<00:03, 20735296.20it/s]\u001b[A\n",
            " 64%|   | 108355584/170498071 [00:06<00:03, 20086355.55it/s]\u001b[A\n",
            " 65%|   | 111484928/170498071 [00:07<00:02, 20325715.66it/s]\u001b[A\n",
            " 67%|   | 114614272/170498071 [00:07<00:02, 20799658.50it/s]\u001b[A\n",
            " 69%|   | 117366784/170498071 [00:07<00:02, 19990101.85it/s]\u001b[A\n",
            " 71%|   | 120479744/170498071 [00:07<00:02, 20378430.10it/s]\u001b[A\n",
            " 73%|  | 123625472/170498071 [00:07<00:02, 20585980.72it/s]\u001b[A\n",
            " 74%|  | 126754816/170498071 [00:07<00:02, 20702533.85it/s]\u001b[A\n",
            " 76%|  | 129523712/170498071 [00:08<00:02, 19949511.10it/s]\u001b[A\n",
            " 78%|  | 132653056/170498071 [00:08<00:01, 20193701.38it/s]\u001b[A\n",
            " 80%|  | 135782400/170498071 [00:08<00:01, 20733182.23it/s]\u001b[A\n",
            " 81%| | 138911744/170498071 [00:08<00:01, 20941729.63it/s]\u001b[A\n",
            " 83%| | 141713408/170498071 [00:08<00:01, 19957720.53it/s]\u001b[A\n",
            " 85%| | 144842752/170498071 [00:08<00:01, 20382688.64it/s]\u001b[A\n",
            " 87%| | 147988480/170498071 [00:08<00:01, 20464717.42it/s]\u001b[A\n",
            " 88%| | 150757376/170498071 [00:09<00:00, 19790706.53it/s]\u001b[A\n",
            " 90%| | 153886720/170498071 [00:09<00:00, 20125190.72it/s]\u001b[A\n",
            " 92%|| 156721152/170498071 [00:09<00:00, 19735173.03it/s]\u001b[A\n",
            " 94%|| 159817728/170498071 [00:09<00:00, 20154901.87it/s]\u001b[A\n",
            " 96%|| 162914304/170498071 [00:09<00:00, 20446142.05it/s]\u001b[A\n",
            " 97%|| 165765120/170498071 [00:09<00:00, 19733045.75it/s]\u001b[A\n",
            " 99%|| 168894464/170498071 [00:09<00:00, 20217801.41it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4kLdhmxEIcH",
        "colab_type": "code",
        "outputId": "8604f641-6a72-4843-b451-fa18017a32a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def fit(model):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "  epochs = 50\n",
        "  running_loss_history = []\n",
        "  running_corrects_history = []\n",
        "  val_running_loss_history = []\n",
        "  val_running_corrects_history = []\n",
        "\n",
        "\n",
        "\n",
        "  for e in range(epochs):\n",
        "  \n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "    val_running_loss = 0.0\n",
        "    val_running_corrects = 0.0\n",
        "    print(e)\n",
        "    for inputs, labels in training_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "    \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      running_loss += loss.item()\n",
        "      running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    else:\n",
        "      with torch.no_grad():\n",
        "        for val_inputs, val_labels in validation_loader:\n",
        "          val_inputs = val_inputs.to(device)\n",
        "          val_labels = val_labels.to(device)\n",
        "          val_outputs = model(val_inputs)\n",
        "          val_loss = criterion(val_outputs, val_labels)\n",
        "        \n",
        "          _, val_preds = torch.max(val_outputs, 1)\n",
        "          val_running_loss += val_loss.item()\n",
        "          val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
        "      epoch_loss = running_loss/len(training_loader)\n",
        "      epoch_acc = running_corrects.float()/ len(training_loader)\n",
        "      running_loss_history.append(epoch_loss)\n",
        "      running_corrects_history.append(epoch_acc)\n",
        "    \n",
        "      val_epoch_loss = val_running_loss/len(validation_loader)\n",
        "      val_epoch_acc = val_running_corrects.float()/ len(validation_loader)\n",
        "      val_running_loss_history.append(val_epoch_loss)\n",
        "      val_running_corrects_history.append(val_epoch_acc)\n",
        "      print('epoch :', (e+1))\n",
        "      print('training loss: {:.4f}, acc {:.4f} '.format(epoch_loss, epoch_acc.item()))\n",
        "      print('validation loss: {:.4f}, validation acc {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "170500096it [00:26, 20217801.41it/s]                               \u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U81P_VgkTvQ3",
        "colab_type": "text"
      },
      "source": [
        "## LNET "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SCtcuEPUy34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 16, 3, 1, padding=1)\n",
        "      self.conv2 = nn.Conv2d(16, 32, 3, 1, padding=1)\n",
        "      self.conv3 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
        "      self.fc1 = nn.Linear(4*4*64, 500)\n",
        "      self.dropout1 = nn.Dropout(0.5)\n",
        "      self.fc2 = nn.Linear(500, 10)\n",
        "    def forward(self, x):\n",
        "      x = F.relu(self.conv1(x))\n",
        "      x = F.max_pool2d(x, 2, 2)\n",
        "      x = F.relu(self.conv2(x))\n",
        "      x = F.max_pool2d(x, 2, 2)\n",
        "      x = F.relu(self.conv3(x))\n",
        "      x = F.max_pool2d(x, 2, 2)\n",
        "      x = x.view(-1, 4*4*64)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.dropout1(x)\n",
        "      x = self.fc2(x)\n",
        "      return x\n",
        "model = LeNet().to(device)\n",
        "# model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpZf3bUnUznx",
        "colab_type": "code",
        "outputId": "416d0551-3645-434f-f46a-9769a4a3f417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fit(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "epoch : 1\n",
            "training loss: 1.9971, acc 27.1240 \n",
            "validation loss: 1.7834, validation acc 36.2200 \n",
            "1\n",
            "epoch : 2\n",
            "training loss: 1.7371, acc 37.1960 \n",
            "validation loss: 1.6167, validation acc 41.3800 \n",
            "2\n",
            "epoch : 3\n",
            "training loss: 1.6333, acc 40.9880 \n",
            "validation loss: 1.5332, validation acc 44.6200 \n",
            "3\n",
            "epoch : 4\n",
            "training loss: 1.5717, acc 43.2460 \n",
            "validation loss: 1.4807, validation acc 46.7500 \n",
            "4\n",
            "epoch : 5\n",
            "training loss: 1.5231, acc 45.0500 \n",
            "validation loss: 1.4374, validation acc 48.4000 \n",
            "5\n",
            "epoch : 6\n",
            "training loss: 1.4867, acc 46.4200 \n",
            "validation loss: 1.4171, validation acc 49.0900 \n",
            "6\n",
            "epoch : 7\n",
            "training loss: 1.4549, acc 47.8080 \n",
            "validation loss: 1.3813, validation acc 50.3400 \n",
            "7\n",
            "epoch : 8\n",
            "training loss: 1.4251, acc 48.9900 \n",
            "validation loss: 1.3402, validation acc 51.9300 \n",
            "8\n",
            "epoch : 9\n",
            "training loss: 1.4059, acc 49.6520 \n",
            "validation loss: 1.3245, validation acc 52.3600 \n",
            "9\n",
            "epoch : 10\n",
            "training loss: 1.3795, acc 50.7860 \n",
            "validation loss: 1.2968, validation acc 53.2500 \n",
            "10\n",
            "epoch : 11\n",
            "training loss: 1.3531, acc 51.5680 \n",
            "validation loss: 1.2731, validation acc 54.7100 \n",
            "11\n",
            "epoch : 12\n",
            "training loss: 1.3378, acc 52.4880 \n",
            "validation loss: 1.2630, validation acc 54.7600 \n",
            "12\n",
            "epoch : 13\n",
            "training loss: 1.3181, acc 53.2660 \n",
            "validation loss: 1.2587, validation acc 54.8300 \n",
            "13\n",
            "epoch : 14\n",
            "training loss: 1.2991, acc 53.9100 \n",
            "validation loss: 1.2284, validation acc 55.9800 \n",
            "14\n",
            "epoch : 15\n",
            "training loss: 1.2772, acc 54.4940 \n",
            "validation loss: 1.2029, validation acc 57.0100 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF3HMPOhTqnw",
        "colab_type": "text"
      },
      "source": [
        "## ONET "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d34PI77HWfhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ONet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv_X1 = nn.Conv2d(3,16,3,1)\n",
        "    self.conv_X2 = nn.Conv2d(16,32,3,1)\n",
        "    self.conv_X3 = nn.Conv2d(32,64,3,1)\n",
        "    \n",
        "   \n",
        "    \n",
        "    self.conv_Xinter = nn.Conv2d(16,32,3,1)\n",
        "    self.conv_Yinter = nn.Conv2d(32,64,3,1)\n",
        "    self.conv_Zinter = nn.Conv2d(64,128,2,1)\n",
        "    \n",
        "    self.fc_Xinter=nn.Linear(1152,1500)\n",
        "    self.fc_Yinter=nn.Linear(256,500)\n",
        "    self.fc_Zinter=nn.Linear(128,500)\n",
        "    \n",
        "    self.fc_Xend=nn.Linear(256,500)\n",
        "    self.fc_Yend=nn.Linear(256,500)\n",
        "    self.fc_Zend =nn.Linear(256,500)\n",
        "    \n",
        "    self.dropout_Xinter = nn.Dropout(0.5)\n",
        "    self.dropout_Yinter = nn.Dropout(0.5)\n",
        "    self.dropout_Zinter = nn.Dropout(0.5)\n",
        "     \n",
        "    self.dropout_Xend = nn.Dropout(0.5)\n",
        "    self.dropout_Yend = nn.Dropout(0.5)\n",
        "    self.dropout_Zend = nn.Dropout(0.5)\n",
        "    \n",
        "#     self.dropout1 =nn.Dropout(0.5)\n",
        "#     self.dropout2 =nn.Dropout(0.5)\n",
        "    \n",
        "    self.fc1 = nn.Linear(3000, 10)\n",
        "#     self.fc2 = nn.Linear(1, 256)\n",
        "#     self.fc3 = nn.Linear(256,10)\n",
        "    \n",
        "#     self.finalfc=nn.Linear(784,256)\n",
        "   \n",
        "\n",
        "  def forward(self,x):\n",
        "    si=x.size(0)\n",
        "    x1 = F.relu(self.conv_X1(x))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    xinter =x1\n",
        "    \n",
        "    x1 = F.relu(self.conv_X2(x1))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    yinter = x1\n",
        "    x1 = F.relu(self.conv_X3(x1))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    zinter = x1\n",
        "    \n",
        "    \n",
        "    \n",
        "    xinter = F.relu(self.conv_Xinter(xinter))\n",
        "    xinter = F.max_pool2d(xinter,2,2)\n",
        "    yinter = F.relu(self.conv_Yinter(yinter))\n",
        "    yinter = F.max_pool2d(yinter,2,2)\n",
        "    zinter = F.relu(self.conv_Zinter(zinter))\n",
        "    zinter = F.max_pool2d(zinter,2,2)\n",
        "    \n",
        "    xinter = xinter.view(si,-1)\n",
        "    xinter = F.relu(self.fc_Xinter(xinter))\n",
        "    xinter = self.dropout_Xinter(xinter)\n",
        "    \n",
        "    yinter = yinter.view(si,-1)\n",
        "    yinter = F.relu(self.fc_Yinter(yinter))\n",
        "    yinter = self.dropout_Yinter(yinter)\n",
        "    \n",
        "    zinter = zinter.view(si,-1)\n",
        "    zinter = F.relu(self.fc_Zinter(zinter))\n",
        "    zinter = self.dropout_Zinter(zinter)\n",
        "    \n",
        "    \n",
        "    X_end = x1.view(si,-1)\n",
        "    X_end = F.relu(self.fc_Xend(X_end))\n",
        "    X_end = self.dropout_Xend(X_end)\n",
        "    \n",
        "     \n",
        "    \n",
        "    flatten=torch.cat((X_end,xinter,yinter,zinter),dim=1)\n",
        "#     flatten=torch.cat((flatten,zinter),dim=1)\n",
        "#     flatten = F.relu(self.fc1(flatten))\n",
        "#     flatten = self.dropout1(flatten)\n",
        "#     flatten  = F.relu(self.fc2(flatten))\n",
        "#     flatten = self.dropout2(flatten)\n",
        "    \n",
        "    return self.fc1(flatten)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "model = ONet().to(device)\n",
        "# model    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb9GutV2ZQ6v",
        "colab_type": "code",
        "outputId": "0299ffe8-2323-4c2a-880c-9a0a6bf926ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fit(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "epoch : 1\n",
            "training loss: 1.8597, acc 32.8320 \n",
            "validation loss: 1.5935, validation acc 42.6900 \n",
            "1\n",
            "epoch : 2\n",
            "training loss: 1.5839, acc 42.8220 \n",
            "validation loss: 1.4728, validation acc 46.5700 \n",
            "2\n",
            "epoch : 3\n",
            "training loss: 1.4994, acc 45.9320 \n",
            "validation loss: 1.3975, validation acc 49.5600 \n",
            "3\n",
            "epoch : 4\n",
            "training loss: 1.4395, acc 48.3500 \n",
            "validation loss: 1.3468, validation acc 51.4900 \n",
            "4\n",
            "epoch : 5\n",
            "training loss: 1.3941, acc 50.3560 \n",
            "validation loss: 1.3039, validation acc 53.6600 \n",
            "5\n",
            "epoch : 6\n",
            "training loss: 1.3552, acc 51.6240 \n",
            "validation loss: 1.2601, validation acc 54.6500 \n",
            "6\n",
            "epoch : 7\n",
            "training loss: 1.3174, acc 52.9760 \n",
            "validation loss: 1.2454, validation acc 55.4500 \n",
            "7\n",
            "epoch : 8\n",
            "training loss: 1.2841, acc 54.4480 \n",
            "validation loss: 1.1950, validation acc 57.2500 \n",
            "8\n",
            "epoch : 9\n",
            "training loss: 1.2547, acc 55.6820 \n",
            "validation loss: 1.1650, validation acc 58.7200 \n",
            "9\n",
            "epoch : 10\n",
            "training loss: 1.2269, acc 56.3100 \n",
            "validation loss: 1.1403, validation acc 59.7600 \n",
            "10\n",
            "epoch : 11\n",
            "training loss: 1.2036, acc 57.5000 \n",
            "validation loss: 1.1171, validation acc 60.0500 \n",
            "11\n",
            "epoch : 12\n",
            "training loss: 1.1854, acc 58.3300 \n",
            "validation loss: 1.1144, validation acc 60.1800 \n",
            "12\n",
            "epoch : 13\n",
            "training loss: 1.1642, acc 59.1760 \n",
            "validation loss: 1.0831, validation acc 61.7100 \n",
            "13\n",
            "epoch : 14\n",
            "training loss: 1.1411, acc 59.8680 \n",
            "validation loss: 1.0768, validation acc 62.0200 \n",
            "14\n",
            "epoch : 15\n",
            "training loss: 1.1262, acc 60.4640 \n",
            "validation loss: 1.0578, validation acc 63.0500 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5zF9NFATlkK",
        "colab_type": "text"
      },
      "source": [
        "## VNet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTVgzSzpXxMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv_X1 = nn.Conv2d(3,16,3,1)\n",
        "    self.conv_X2 = nn.Conv2d(16,32,3,1)\n",
        "    self.conv_X3 = nn.Conv2d(32,64,3,1)\n",
        "    \n",
        "    self.conv_Y1 = nn.Conv2d(3,16,3,1)\n",
        "    self.conv_Y2 = nn.Conv2d(16,32,3,1)\n",
        "    self.conv_Y3 = nn.Conv2d(32,64,3,1)\n",
        "    \n",
        "    self.conv_Z1 = nn.Conv2d(3,16,3,1)\n",
        "    self.conv_Z2 = nn.Conv2d(16,32,3,1)\n",
        "    self.conv_Z3 = nn.Conv2d(32,64,3,1)\n",
        "    \n",
        "    self.conv_Xinter = nn.Conv2d(16,32,3,1)\n",
        "    self.conv_Yinter = nn.Conv2d(32,64,3,1)\n",
        "    self.conv_Zinter = nn.Conv2d(64,128,2,1)\n",
        "    \n",
        "    self.fc1=nn.Linear(1152,1500)\n",
        "    self.fc2=nn.Linear(256,500)\n",
        "    self.fc3=nn.Linear(128,500)\n",
        "    self.dropout1 = nn.Dropout(0.5)\n",
        "    self.fc = nn.Linear(2500, 10)\n",
        "#     self.fclast=nn.Linear(784,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    si=x.size(0)\n",
        "#     print(si)\n",
        "    x1 = F.relu(self.conv_X1(x))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    xinter =x1\n",
        "    \n",
        "#     x1 = F.relu(self.conv_X2(x1))\n",
        "#     x1 = F.max_pool2d(x1,2,2)\n",
        "#     x1 = F.relu(self.conv_X3(x1))\n",
        "#     x1 = F.max_pool2d(x1,2,2)\n",
        "    \n",
        "    x2 = F.relu(self.conv_Y1(x))\n",
        "    x2 = F.max_pool2d(x2,2,2)\n",
        "    x2 = F.relu(self.conv_Y2(x2))\n",
        "    x2 = F.max_pool2d(x2,2,2)\n",
        "    yinter = x2\n",
        "#     x2 = F.relu(self.conv_Y3(x2))\n",
        "#     x2= F.max_pool2d(x2,2,2)\n",
        "    \n",
        "    x3 = F.relu(self.conv_Z1(x))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    x3 = F.relu(self.conv_Z2(x3))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    x3 = F.relu(self.conv_Z3(x3))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    zinter=x3\n",
        "    \n",
        "    xinter = F.relu(self.conv_Xinter(xinter))\n",
        "    xinter = F.max_pool2d(xinter,2,2)\n",
        "    yinter = F.relu(self.conv_Yinter(yinter))\n",
        "    yinter = F.max_pool2d(yinter,2,2)\n",
        "    zinter = F.relu(self.conv_Zinter(zinter))\n",
        "    zinter = F.max_pool2d(zinter,2,2)\n",
        "    \n",
        "    xinter = xinter.view(si,-1)\n",
        "#     print(xinter.shape)\n",
        "    xinter = F.relu(self.fc1(xinter))\n",
        "    xinter = self.dropout1(xinter)\n",
        "    \n",
        "    yinter = yinter.view(si,-1)\n",
        "    yinter = F.relu(self.fc2(yinter))\n",
        "    yinter = self.dropout1(yinter)\n",
        "    \n",
        "    zinter = zinter.view(si,-1)\n",
        "    zinter = F.relu(self.fc3(zinter))\n",
        "    zinter = self.dropout1(zinter)\n",
        "    \n",
        "    flatten=torch.cat((xinter,yinter,zinter),dim=1)\n",
        "#     flatten=F.relu(self.fc(flatten))\n",
        "#     flatten=self.dropout1(flatten)\n",
        "#     flatten=torch.cat((flatten,zinter),dim=1)\n",
        "    \n",
        "    return self.fc(flatten)\n",
        "    \n",
        "    \n",
        "    \n",
        "model=VNet().to(device)\n",
        "# model\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AmKzuvkZOcZ",
        "colab_type": "code",
        "outputId": "ba9a14f7-6369-46f5-9e13-31876184f620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fit(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "epoch : 1\n",
            "training loss: 1.8638, acc 32.6840 \n",
            "validation loss: 1.5922, validation acc 43.3900 \n",
            "1\n",
            "epoch : 2\n",
            "training loss: 1.5863, acc 42.8520 \n",
            "validation loss: 1.4511, validation acc 47.9600 \n",
            "2\n",
            "epoch : 3\n",
            "training loss: 1.4871, acc 46.5120 \n",
            "validation loss: 1.3900, validation acc 50.4400 \n",
            "3\n",
            "epoch : 4\n",
            "training loss: 1.4255, acc 48.5760 \n",
            "validation loss: 1.3312, validation acc 52.0600 \n",
            "4\n",
            "epoch : 5\n",
            "training loss: 1.3810, acc 50.7720 \n",
            "validation loss: 1.2885, validation acc 54.2300 \n",
            "5\n",
            "epoch : 6\n",
            "training loss: 1.3371, acc 52.4340 \n",
            "validation loss: 1.2589, validation acc 55.4400 \n",
            "6\n",
            "epoch : 7\n",
            "training loss: 1.3082, acc 53.6480 \n",
            "validation loss: 1.2280, validation acc 56.4100 \n",
            "7\n",
            "epoch : 8\n",
            "training loss: 1.2772, acc 54.8120 \n",
            "validation loss: 1.2070, validation acc 56.5600 \n",
            "8\n",
            "epoch : 9\n",
            "training loss: 1.2507, acc 55.6380 \n",
            "validation loss: 1.1677, validation acc 58.4000 \n",
            "9\n",
            "epoch : 10\n",
            "training loss: 1.2240, acc 56.8820 \n",
            "validation loss: 1.1348, validation acc 59.6500 \n",
            "10\n",
            "epoch : 11\n",
            "training loss: 1.1983, acc 57.6060 \n",
            "validation loss: 1.1215, validation acc 60.2000 \n",
            "11\n",
            "epoch : 12\n",
            "training loss: 1.1758, acc 58.5040 \n",
            "validation loss: 1.0968, validation acc 61.1700 \n",
            "12\n",
            "epoch : 13\n",
            "training loss: 1.1574, acc 59.2700 \n",
            "validation loss: 1.0855, validation acc 61.9800 \n",
            "13\n",
            "epoch : 14\n",
            "training loss: 1.1370, acc 59.7920 \n",
            "validation loss: 1.0619, validation acc 62.1700 \n",
            "14\n",
            "epoch : 15\n",
            "training loss: 1.1226, acc 60.3980 \n",
            "validation loss: 1.0580, validation acc 62.4300 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z12H7aUfTf53",
        "colab_type": "text"
      },
      "source": [
        "## VNET MODIFIED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35-M2J5mX3Ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VNetModified(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv_X1 = nn.Conv2d(3,16,3,1)\n",
        "    self.conv_X2 = nn.Conv2d(16,32,3,1)\n",
        "    self.conv_X3 = nn.Conv2d(32,64,3,1)\n",
        "    \n",
        "    self.conv_Y1 = nn.Conv2d(3,16,3,1)\n",
        "    self.conv_Y2 = nn.Conv2d(16,32,3,1)\n",
        "    self.conv_Y3 = nn.Conv2d(32,64,3,1)\n",
        "    \n",
        "    \n",
        "    self.conv_Z1 = nn.Conv2d(3,16,3,1)\n",
        "    self.conv_Z2 = nn.Conv2d(16,32,3,1)\n",
        "    self.conv_Z3 = nn.Conv2d(32,64,3,1)\n",
        "    \n",
        "    self.conv_Xinter = nn.Conv2d(16,32,3,1)\n",
        "    self.conv_Yinter = nn.Conv2d(32,64,3,1)\n",
        "    self.conv_Zinter = nn.Conv2d(64,128,2,1)\n",
        "    \n",
        "    self.fc_Xinter=nn.Linear(1152,1500)\n",
        "    self.fc_Yinter=nn.Linear(256,500)\n",
        "    self.fc_Zinter=nn.Linear(128,500)\n",
        "    \n",
        "    self.fc_Xend=nn.Linear(256,500)\n",
        "    self.fc_Yend=nn.Linear(256,500)\n",
        "    self.fc_Zend =nn.Linear(256,500)\n",
        "    \n",
        "    self.dropout_Xinter = nn.Dropout(0.5)\n",
        "    self.dropout_Yinter = nn.Dropout(0.5)\n",
        "    self.dropout_Zinter = nn.Dropout(0.5)\n",
        "     \n",
        "    self.dropout_Xend = nn.Dropout(0.5)\n",
        "    self.dropout_Yend = nn.Dropout(0.5)\n",
        "    self.dropout_Zend = nn.Dropout(0.5)\n",
        "    \n",
        "    self.dropout1 =nn.Dropout(0.5)\n",
        "    self.dropout2 =nn.Dropout(0.5)\n",
        "    \n",
        "    self.fc1 = nn.Linear(4000, 10)\n",
        "#     self.fc2 = nn.Linear(1, 256)\n",
        "#     self.fc3 = nn.Linear(256,10)\n",
        "    \n",
        "#     self.finalfc=nn.Linear(784,256)\n",
        "   \n",
        "\n",
        "  def forward(self,x):\n",
        "    si=x.size(0)\n",
        "    x1 = F.relu(self.conv_X1(x))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    xinter =x1\n",
        "    \n",
        "    x1 = F.relu(self.conv_X2(x1))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    x1 = F.relu(self.conv_X3(x1))\n",
        "    x1 = F.max_pool2d(x1,2,2)\n",
        "    \n",
        "    x2 = F.relu(self.conv_Y1(x))\n",
        "    x2 = F.max_pool2d(x2,2,2)\n",
        "    x2 = F.relu(self.conv_Y2(x2))\n",
        "    x2 = F.max_pool2d(x2,2,2)\n",
        "    yinter = x2\n",
        "    x2 = F.relu(self.conv_Y3(x2))\n",
        "    x2= F.max_pool2d(x2,2,2)\n",
        "    \n",
        "    x3 = F.relu(self.conv_Z1(x))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    x3 = F.relu(self.conv_Z2(x3))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    x3 = F.relu(self.conv_Z3(x3))\n",
        "    x3 = F.max_pool2d(x3,2,2)\n",
        "    zinter=x3\n",
        "    \n",
        "    xinter = F.relu(self.conv_Xinter(xinter))\n",
        "    xinter = F.max_pool2d(xinter,2,2)\n",
        "    yinter = F.relu(self.conv_Yinter(yinter))\n",
        "    yinter = F.max_pool2d(yinter,2,2)\n",
        "    zinter = F.relu(self.conv_Zinter(zinter))\n",
        "    zinter = F.max_pool2d(zinter,2,2)\n",
        "    \n",
        "    xinter = xinter.view(si,-1)\n",
        "    xinter = F.relu(self.fc_Xinter(xinter))\n",
        "    xinter = self.dropout_Xinter(xinter)\n",
        "    \n",
        "    yinter = yinter.view(si,-1)\n",
        "    yinter = F.relu(self.fc_Yinter(yinter))\n",
        "    yinter = self.dropout_Yinter(yinter)\n",
        "    \n",
        "    zinter = zinter.view(si,-1)\n",
        "    zinter = F.relu(self.fc_Zinter(zinter))\n",
        "    zinter = self.dropout_Zinter(zinter)\n",
        "    \n",
        "    \n",
        "    X_end = x1.view(si,-1)\n",
        "    X_end = F.relu(self.fc_Xend(X_end))\n",
        "    X_end = self.dropout_Xend(X_end)\n",
        "    \n",
        "     \n",
        "    Y_end = x2.view(si,-1)\n",
        "    Y_end = F.relu(self.fc_Yend(Y_end))\n",
        "    Y_end = self.dropout_Yend(Y_end)\n",
        "     \n",
        "    Z_end = x3.view(si,-1)\n",
        "    Z_end = F.relu(self.fc_Zend(Z_end))\n",
        "    Z_end = self.dropout_Zend(Z_end)\n",
        "    \n",
        "    flatten=torch.cat((X_end,Y_end,Z_end,xinter,yinter,zinter),dim=1)\n",
        "#     flatten=torch.cat((flatten,zinter),dim=1)\n",
        "#     flatten = F.relu(self.fc1(flatten))\n",
        "#     flatten = self.dropout1(flatten)\n",
        "#     flatten  = F.relu(self.fc2(flatten))\n",
        "#     flatten = self.dropout2(flatten)\n",
        "    \n",
        "    return self.fc1(flatten)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "model = VNetModified().to(device)\n",
        "# model    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C7mEYNZisq0",
        "colab_type": "code",
        "outputId": "e8ab739e-7188-4263-e8f1-6f2c23707ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VNetModified(\n",
              "  (conv_X1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_X2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_X3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_Y1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_Y2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_Y3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_Z1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_Z2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_Z3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_Xinter): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_Yinter): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv_Zinter): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (fc_Xinter): Linear(in_features=1152, out_features=1500, bias=True)\n",
              "  (fc_Yinter): Linear(in_features=256, out_features=500, bias=True)\n",
              "  (fc_Zinter): Linear(in_features=128, out_features=500, bias=True)\n",
              "  (fc_Xend): Linear(in_features=256, out_features=500, bias=True)\n",
              "  (fc_Yend): Linear(in_features=256, out_features=500, bias=True)\n",
              "  (fc_Zend): Linear(in_features=256, out_features=500, bias=True)\n",
              "  (dropout_Xinter): Dropout(p=0.5)\n",
              "  (dropout_Yinter): Dropout(p=0.5)\n",
              "  (dropout_Zinter): Dropout(p=0.5)\n",
              "  (dropout_Xend): Dropout(p=0.5)\n",
              "  (dropout_Yend): Dropout(p=0.5)\n",
              "  (dropout_Zend): Dropout(p=0.5)\n",
              "  (dropout1): Dropout(p=0.5)\n",
              "  (dropout2): Dropout(p=0.5)\n",
              "  (fc1): Linear(in_features=4000, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmnht5lKZLCm",
        "colab_type": "code",
        "outputId": "9e20ea52-ca68-435c-c339-3e48f2b87bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fit(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "epoch : 1\n",
            "training loss: 1.8458, acc 33.7260 \n",
            "validation loss: 1.5861, validation acc 43.2300 \n",
            "1\n",
            "epoch : 2\n",
            "training loss: 1.5583, acc 43.9340 \n",
            "validation loss: 1.4287, validation acc 49.7800 \n",
            "2\n",
            "epoch : 3\n",
            "training loss: 1.4557, acc 47.8880 \n",
            "validation loss: 1.3572, validation acc 52.0000 \n",
            "3\n",
            "epoch : 4\n",
            "training loss: 1.3882, acc 50.5340 \n",
            "validation loss: 1.2904, validation acc 54.3600 \n",
            "4\n",
            "epoch : 5\n",
            "training loss: 1.3359, acc 52.7740 \n",
            "validation loss: 1.2435, validation acc 56.2000 \n",
            "5\n",
            "epoch : 6\n",
            "training loss: 1.2937, acc 54.4020 \n",
            "validation loss: 1.2113, validation acc 56.6500 \n",
            "6\n",
            "epoch : 7\n",
            "training loss: 1.2609, acc 55.4300 \n",
            "validation loss: 1.1808, validation acc 58.3900 \n",
            "7\n",
            "epoch : 8\n",
            "training loss: 1.2220, acc 57.1620 \n",
            "validation loss: 1.1436, validation acc 59.3900 \n",
            "8\n",
            "epoch : 9\n",
            "training loss: 1.1969, acc 57.7920 \n",
            "validation loss: 1.1190, validation acc 60.7900 \n",
            "9\n",
            "epoch : 10\n",
            "training loss: 1.1745, acc 58.7400 \n",
            "validation loss: 1.0792, validation acc 62.2700 \n",
            "10\n",
            "epoch : 11\n",
            "training loss: 1.1430, acc 60.0960 \n",
            "validation loss: 1.0649, validation acc 62.3300 \n",
            "11\n",
            "epoch : 12\n",
            "training loss: 1.1221, acc 60.5960 \n",
            "validation loss: 1.0546, validation acc 62.8900 \n",
            "12\n",
            "epoch : 13\n",
            "training loss: 1.1047, acc 61.3360 \n",
            "validation loss: 1.0343, validation acc 63.6100 \n",
            "13\n",
            "epoch : 14\n",
            "training loss: 1.0838, acc 62.1340 \n",
            "validation loss: 1.0229, validation acc 64.3200 \n",
            "14\n",
            "epoch : 15\n",
            "training loss: 1.0710, acc 62.5780 \n",
            "validation loss: 0.9903, validation acc 65.2600 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwqzhPNeTOHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJlrOXSaTPUg",
        "colab_type": "text"
      },
      "source": [
        "## 50 epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIL8_emcTa_Q",
        "colab_type": "code",
        "outputId": "11dd32cc-e2e4-40ad-d0d1-3c53a8ea5e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fit(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "epoch : 1\n",
            "training loss: 1.8703, acc 32.5460 \n",
            "validation loss: 1.5818, validation acc 43.3900 \n",
            "1\n",
            "epoch : 2\n",
            "training loss: 1.5733, acc 43.4600 \n",
            "validation loss: 1.4479, validation acc 48.2300 \n",
            "2\n",
            "epoch : 3\n",
            "training loss: 1.4735, acc 47.3100 \n",
            "validation loss: 1.3631, validation acc 51.3700 \n",
            "3\n",
            "epoch : 4\n",
            "training loss: 1.4036, acc 49.8400 \n",
            "validation loss: 1.2990, validation acc 54.0500 \n",
            "4\n",
            "epoch : 5\n",
            "training loss: 1.3497, acc 51.9960 \n",
            "validation loss: 1.2453, validation acc 56.1500 \n",
            "5\n",
            "epoch : 6\n",
            "training loss: 1.3075, acc 53.7560 \n",
            "validation loss: 1.2184, validation acc 56.6000 \n",
            "6\n",
            "epoch : 7\n",
            "training loss: 1.2726, acc 54.9880 \n",
            "validation loss: 1.1834, validation acc 58.3500 \n",
            "7\n",
            "epoch : 8\n",
            "training loss: 1.2352, acc 56.5680 \n",
            "validation loss: 1.1551, validation acc 59.2500 \n",
            "8\n",
            "epoch : 9\n",
            "training loss: 1.2058, acc 57.3940 \n",
            "validation loss: 1.1067, validation acc 61.0100 \n",
            "9\n",
            "epoch : 10\n",
            "training loss: 1.1818, acc 58.5400 \n",
            "validation loss: 1.0985, validation acc 61.2100 \n",
            "10\n",
            "epoch : 11\n",
            "training loss: 1.1532, acc 59.5800 \n",
            "validation loss: 1.0695, validation acc 62.3500 \n",
            "11\n",
            "epoch : 12\n",
            "training loss: 1.1331, acc 60.3880 \n",
            "validation loss: 1.0770, validation acc 61.8400 \n",
            "12\n",
            "epoch : 13\n",
            "training loss: 1.1114, acc 61.0740 \n",
            "validation loss: 1.0397, validation acc 63.5800 \n",
            "13\n",
            "epoch : 14\n",
            "training loss: 1.0956, acc 61.9300 \n",
            "validation loss: 1.0130, validation acc 64.7900 \n",
            "14\n",
            "epoch : 15\n",
            "training loss: 1.0730, acc 62.6360 \n",
            "validation loss: 1.0002, validation acc 65.1600 \n",
            "15\n",
            "epoch : 16\n",
            "training loss: 1.0562, acc 63.2940 \n",
            "validation loss: 0.9985, validation acc 65.2400 \n",
            "16\n",
            "epoch : 17\n",
            "training loss: 1.0416, acc 63.6900 \n",
            "validation loss: 0.9759, validation acc 66.1600 \n",
            "17\n",
            "epoch : 18\n",
            "training loss: 1.0257, acc 64.2420 \n",
            "validation loss: 0.9591, validation acc 66.4300 \n",
            "18\n",
            "epoch : 19\n",
            "training loss: 1.0102, acc 64.6340 \n",
            "validation loss: 0.9567, validation acc 66.7700 \n",
            "19\n",
            "epoch : 20\n",
            "training loss: 0.9963, acc 65.3240 \n",
            "validation loss: 0.9575, validation acc 66.6900 \n",
            "20\n",
            "epoch : 21\n",
            "training loss: 0.9827, acc 65.6540 \n",
            "validation loss: 0.9179, validation acc 67.7400 \n",
            "21\n",
            "epoch : 22\n",
            "training loss: 0.9716, acc 66.2240 \n",
            "validation loss: 0.9279, validation acc 67.8300 \n",
            "22\n",
            "epoch : 23\n",
            "training loss: 0.9599, acc 66.7340 \n",
            "validation loss: 0.9096, validation acc 68.2600 \n",
            "23\n",
            "epoch : 24\n",
            "training loss: 0.9483, acc 67.1480 \n",
            "validation loss: 0.9199, validation acc 68.2000 \n",
            "24\n",
            "epoch : 25\n",
            "training loss: 0.9386, acc 67.5220 \n",
            "validation loss: 0.8977, validation acc 68.6700 \n",
            "25\n",
            "epoch : 26\n",
            "training loss: 0.9288, acc 68.0400 \n",
            "validation loss: 0.8709, validation acc 69.7000 \n",
            "26\n",
            "epoch : 27\n",
            "training loss: 0.9139, acc 68.2560 \n",
            "validation loss: 0.8806, validation acc 69.6000 \n",
            "27\n",
            "epoch : 28\n",
            "training loss: 0.9093, acc 68.4060 \n",
            "validation loss: 0.8586, validation acc 69.9000 \n",
            "28\n",
            "epoch : 29\n",
            "training loss: 0.8969, acc 68.8300 \n",
            "validation loss: 0.8593, validation acc 70.2800 \n",
            "29\n",
            "epoch : 30\n",
            "training loss: 0.8899, acc 69.0840 \n",
            "validation loss: 0.8639, validation acc 70.0600 \n",
            "30\n",
            "epoch : 31\n",
            "training loss: 0.8769, acc 69.6320 \n",
            "validation loss: 0.8348, validation acc 71.0900 \n",
            "31\n",
            "epoch : 32\n",
            "training loss: 0.8664, acc 69.9160 \n",
            "validation loss: 0.8444, validation acc 70.4900 \n",
            "32\n",
            "epoch : 33\n",
            "training loss: 0.8587, acc 70.2780 \n",
            "validation loss: 0.8320, validation acc 71.3800 \n",
            "33\n",
            "epoch : 34\n",
            "training loss: 0.8518, acc 70.5140 \n",
            "validation loss: 0.8263, validation acc 71.2500 \n",
            "34\n",
            "epoch : 35\n",
            "training loss: 0.8494, acc 70.5160 \n",
            "validation loss: 0.8103, validation acc 72.0300 \n",
            "35\n",
            "epoch : 36\n",
            "training loss: 0.8392, acc 71.0480 \n",
            "validation loss: 0.8123, validation acc 72.1600 \n",
            "36\n",
            "epoch : 37\n",
            "training loss: 0.8242, acc 71.5160 \n",
            "validation loss: 0.8041, validation acc 72.0100 \n",
            "37\n",
            "epoch : 38\n",
            "training loss: 0.8218, acc 71.5680 \n",
            "validation loss: 0.7982, validation acc 72.7100 \n",
            "38\n",
            "epoch : 39\n",
            "training loss: 0.8115, acc 71.9540 \n",
            "validation loss: 0.8043, validation acc 72.1000 \n",
            "39\n",
            "epoch : 40\n",
            "training loss: 0.8045, acc 72.2740 \n",
            "validation loss: 0.7887, validation acc 72.6900 \n",
            "40\n",
            "epoch : 41\n",
            "training loss: 0.7965, acc 72.3540 \n",
            "validation loss: 0.7823, validation acc 72.9900 \n",
            "41\n",
            "epoch : 42\n",
            "training loss: 0.7957, acc 72.6400 \n",
            "validation loss: 0.7741, validation acc 73.3800 \n",
            "42\n",
            "epoch : 43\n",
            "training loss: 0.7847, acc 72.9060 \n",
            "validation loss: 0.7794, validation acc 73.2800 \n",
            "43\n",
            "epoch : 44\n",
            "training loss: 0.7753, acc 73.1240 \n",
            "validation loss: 0.7750, validation acc 73.2700 \n",
            "44\n",
            "epoch : 45\n",
            "training loss: 0.7654, acc 73.3620 \n",
            "validation loss: 0.7786, validation acc 73.3400 \n",
            "45\n",
            "epoch : 46\n",
            "training loss: 0.7628, acc 73.4280 \n",
            "validation loss: 0.7781, validation acc 73.1900 \n",
            "46\n",
            "epoch : 47\n",
            "training loss: 0.7531, acc 73.8120 \n",
            "validation loss: 0.7646, validation acc 73.6400 \n",
            "47\n",
            "epoch : 48\n",
            "training loss: 0.7512, acc 74.1760 \n",
            "validation loss: 0.7807, validation acc 72.9500 \n",
            "48\n",
            "epoch : 49\n",
            "training loss: 0.7475, acc 74.0340 \n",
            "validation loss: 0.7523, validation acc 74.4100 \n",
            "49\n",
            "epoch : 50\n",
            "training loss: 0.7411, acc 74.2440 \n",
            "validation loss: 0.7609, validation acc 73.7600 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}